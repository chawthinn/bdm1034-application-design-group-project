{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4404378-b514-4946-9846-aaa8701a1e0a",
   "metadata": {},
   "source": [
    "## Dividend Data from Yahoo Finance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525c19f-e180-4c43-84e0-81218a1c6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"ABT\", \"AGG\", \"AMD\", \"AMGN\", \"AMZN\", \"ANET\", \"ARKK\", \"ATI\", \"AVGO\", \"BA\",\n",
    "    \"BAC\", \"BMO\", \"BND\", \"C\", \"CAT\", \"CELH\", \"CLS\", \"CM\", \"CNQ\", \"COKE\", \"COST\", \"CRM\",\n",
    "    \"CRWD\", \"CVNA\", \"CVX\", \"DBA\", \"DDOG\", \"DIA\", \"EA\", \"EEM\", \"EFA\", \"ENB\", \"FICO\",\n",
    "    \"FIX\", \"GLD\", \"GNOM\", \"GOOGL\", \"GS\", \"HYG\", \"IBM\", \"ICLN\", \"IEF\", \"INTC\", \"INVA\",\n",
    "    \"IWM\", \"JNJ\", \"JPM\", \"KO\", \"LLY\", \"LQD\", \"MA\", \"META\", \"MMM\", \"MRK\", \"MRVL\", \"MS\",\n",
    "    \"MSFT\", \"MSTR\", \"NFLX\", \"NVDA\", \"ORCL\", \"PDBC\", \"PEP\", \"PFE\", \"PG\", \"PLTR\", \"PYPL\",\n",
    "    \"QQQ\", \"RIVN\", \"RY\", \"SHOP\", \"SHY\", \"SLV\", \"SNOW\", \"SPY\", \"SU\", \"TAN\", \"TCEHY\",\n",
    "    \"TD\", \"TLT\", \"TMO\", \"TSLA\", \"TSM\", \"TTD\", \"UBER\", \"UNG\", \"UNH\", \"USO\", \"V\", \"VEA\",\n",
    "    \"VKTX\", \"VRT\", \"VST\", \"VWO\", \"WEAT\", \"WMT\", \"XBB\", \"XLE\", \"XLF\", \"XLK\", \"XLV\", \"XLY\",\n",
    "    \"XOM\", \"ZG\"\n",
    "]\n",
    "\n",
    "# Initialize a list to store the summary data\n",
    "dividend_data = []\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Fetch the stock data\n",
    "        stock = yf.Ticker(ticker)\n",
    "        dividends = stock.dividends  # Get the dividend history\n",
    "\n",
    "        if not dividends.empty:\n",
    "            # Ensure dates are sorted\n",
    "            dividends = dividends.sort_index()\n",
    "\n",
    "            # Calculate average dividend per share\n",
    "            avg_dividend = dividends.mean()\n",
    "\n",
    "            # Determine the frequency of dividend payments based on intervals\n",
    "            intervals = dividends.index.to_series().diff().dt.days.dropna()\n",
    "            avg_interval = intervals.mean()\n",
    "            if avg_interval <= 45:\n",
    "                frequency = \"Monthly\"\n",
    "            elif avg_interval <= 135:\n",
    "                frequency = \"Quarterly\"\n",
    "            elif avg_interval <= 225:\n",
    "                frequency = \"Semi-Annual\"\n",
    "            else:\n",
    "                frequency = \"Annual\"\n",
    "        else:\n",
    "            # If no dividend history exists\n",
    "            avg_dividend = \"N/A\"\n",
    "            frequency = \"N/A\"\n",
    "    except Exception as e:\n",
    "        # Handle errors and log N/A for problematic tickers\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        avg_dividend = \"N/A\"\n",
    "        frequency = \"N/A\"\n",
    "\n",
    "    # Append the result to the list\n",
    "    dividend_data.append({\n",
    "        \"Ticker\": ticker,\n",
    "        \"Dividend Frequency\": frequency,\n",
    "        \"Average Dividend per Share\": avg_dividend\n",
    "    })\n",
    "\n",
    "# Convert the summary data to a DataFrame\n",
    "dividend_df = pd.DataFrame(dividend_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "dividend_df.to_csv(\"dividend_summary_all_tickers.csv\", index=False)\n",
    "\n",
    "# Display the summary\n",
    "print(dividend_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8becc6b-6cad-4f11-a154-4c14943cd0e5",
   "metadata": {},
   "source": [
    "## Insert the info in mongodb collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a05cefbd-b782-4c58-aad2-db1157a03ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker AAPL already has the fields. Skipping update.\n",
      "Updated Ticker ABT with new fields.\n",
      "Ticker AGG already has the fields. Skipping update.\n",
      "Updated Ticker AMD with new fields.\n",
      "Updated Ticker AMGN with new fields.\n",
      "Updated Ticker AMZN with new fields.\n",
      "Updated Ticker ANET with new fields.\n",
      "Updated Ticker ARKK with new fields.\n",
      "Updated Ticker ATI with new fields.\n",
      "Updated Ticker AVGO with new fields.\n",
      "Updated Ticker BA with new fields.\n",
      "Ticker BAC already has the fields. Skipping update.\n",
      "Updated Ticker BMO with new fields.\n",
      "Ticker BND already has the fields. Skipping update.\n",
      "Ticker C already has the fields. Skipping update.\n",
      "Updated Ticker CAT with new fields.\n",
      "Updated Ticker CELH with new fields.\n",
      "Updated Ticker CLS with new fields.\n",
      "Updated Ticker CM with new fields.\n",
      "Updated Ticker CNQ with new fields.\n",
      "Updated Ticker COKE with new fields.\n",
      "Ticker COST already has the fields. Skipping update.\n",
      "Updated Ticker CRM with new fields.\n",
      "Updated Ticker CRWD with new fields.\n",
      "Updated Ticker CVNA with new fields.\n",
      "Updated Ticker CVX with new fields.\n",
      "Updated Ticker DBA with new fields.\n",
      "Updated Ticker DDOG with new fields.\n",
      "Ticker DIA already has the fields. Skipping update.\n",
      "Updated Ticker EA with new fields.\n",
      "Ticker EEM already has the fields. Skipping update.\n",
      "Ticker EFA already has the fields. Skipping update.\n",
      "Updated Ticker ENB with new fields.\n",
      "Updated Ticker FICO with new fields.\n",
      "Updated Ticker FIX with new fields.\n",
      "Ticker GLD already has the fields. Skipping update.\n",
      "Updated Ticker GNOM with new fields.\n",
      "Ticker GOOGL already has the fields. Skipping update.\n",
      "Ticker GS already has the fields. Skipping update.\n",
      "Ticker HYG already has the fields. Skipping update.\n",
      "Ticker IBM already has the fields. Skipping update.\n",
      "Updated Ticker ICLN with new fields.\n",
      "Ticker IEF already has the fields. Skipping update.\n",
      "Updated Ticker INTC with new fields.\n",
      "Updated Ticker INVA with new fields.\n",
      "Ticker IWM already has the fields. Skipping update.\n",
      "Ticker JNJ already has the fields. Skipping update.\n",
      "Ticker JPM already has the fields. Skipping update.\n",
      "Ticker KO already has the fields. Skipping update.\n",
      "Updated Ticker LLY with new fields.\n",
      "Ticker LQD already has the fields. Skipping update.\n",
      "Updated Ticker MA with new fields.\n",
      "Updated Ticker META with new fields.\n",
      "Updated Ticker MMM with new fields.\n",
      "Ticker MRK already has the fields. Skipping update.\n",
      "Updated Ticker MRVL with new fields.\n",
      "Ticker MS already has the fields. Skipping update.\n",
      "Ticker MSFT already has the fields. Skipping update.\n",
      "Updated Ticker MSTR with new fields.\n",
      "Updated Ticker NFLX with new fields.\n",
      "Updated Ticker NVDA with new fields.\n",
      "Updated Ticker ORCL with new fields.\n",
      "Ticker PDBC already has the fields. Skipping update.\n",
      "Ticker PEP already has the fields. Skipping update.\n",
      "Ticker PFE already has the fields. Skipping update.\n",
      "Ticker PG already has the fields. Skipping update.\n",
      "Updated Ticker PLTR with new fields.\n",
      "Updated Ticker PYPL with new fields.\n",
      "Ticker QQQ already has the fields. Skipping update.\n",
      "Updated Ticker RIVN with new fields.\n",
      "Updated Ticker RY with new fields.\n",
      "Updated Ticker SHOP with new fields.\n",
      "Ticker SHY already has the fields. Skipping update.\n",
      "Ticker SLV already has the fields. Skipping update.\n",
      "Updated Ticker SNOW with new fields.\n",
      "Ticker SPY already has the fields. Skipping update.\n",
      "Updated Ticker SU with new fields.\n",
      "Updated Ticker TAN with new fields.\n",
      "Updated Ticker TCEHY with new fields.\n",
      "Updated Ticker TD with new fields.\n",
      "Ticker TLT already has the fields. Skipping update.\n",
      "Updated Ticker TMO with new fields.\n",
      "Ticker TSLA already has the fields. Skipping update.\n",
      "Updated Ticker TSM with new fields.\n",
      "Updated Ticker TTD with new fields.\n",
      "Updated Ticker UBER with new fields.\n",
      "Ticker UNG already has the fields. Skipping update.\n",
      "Ticker UNH already has the fields. Skipping update.\n",
      "Ticker USO already has the fields. Skipping update.\n",
      "Updated Ticker V with new fields.\n",
      "Ticker VEA already has the fields. Skipping update.\n",
      "Updated Ticker VKTX with new fields.\n",
      "Updated Ticker VRT with new fields.\n",
      "Updated Ticker VST with new fields.\n",
      "Ticker VWO already has the fields. Skipping update.\n",
      "Updated Ticker WEAT with new fields.\n",
      "Ticker WMT already has the fields. Skipping update.\n",
      "Updated Ticker XBB with new fields.\n",
      "Ticker XLE already has the fields. Skipping update.\n",
      "Ticker XLF already has the fields. Skipping update.\n",
      "Ticker XLK already has the fields. Skipping update.\n",
      "Ticker XLV already has the fields. Skipping update.\n",
      "Ticker XLY already has the fields. Skipping update.\n",
      "Updated Ticker XOM with new fields.\n",
      "Updated Ticker ZG with new fields.\n",
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://user1:12345@cluster0.s5hw0.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "db = client[\"robo_advisor\"]\n",
    "collection = db[\"asset_metadata\"]\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = \"dividend_summary_all_tickers.csv\" \n",
    "dividend_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Loop through each row in the CSV file\n",
    "for index, row in dividend_data.iterrows():\n",
    "    ticker = row[\"Ticker\"]\n",
    "    dividend_frequency = row[\"Dividend Frequency\"]\n",
    "    avg_dividend_per_share = row[\"Average Dividend per Share\"]\n",
    "\n",
    "    # Check if the document exists and if the fields are already present\n",
    "    existing_record = collection.find_one({\"Ticker\": ticker})\n",
    "\n",
    "    if existing_record:\n",
    "        # Check if \"Dividend Frequency\" and \"Average Dividend per Share\" exist\n",
    "        if \"Dividend Frequency\" in existing_record and \"Average Dividend per Share\" in existing_record:\n",
    "            print(f\"Ticker {ticker} already has the fields. Skipping update.\")\n",
    "        else:\n",
    "            # Update the existing document with the new fields\n",
    "            collection.update_one(\n",
    "                {\"Ticker\": ticker},\n",
    "                {\"$set\": {\n",
    "                    \"Dividend Frequency\": dividend_frequency,\n",
    "                    \"Average Dividend per Share\": avg_dividend_per_share\n",
    "                }}\n",
    "            )\n",
    "            print(f\"Updated Ticker {ticker} with new fields.\")\n",
    "    else:\n",
    "        # If the ticker doesn't exist in the collection\n",
    "        print(f\"Ticker {ticker} not found in the collection. Skipping.\")\n",
    "\n",
    "print(\"Process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8a46d74-5aa0-4d83-b5c4-2c533a7c4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document with _id: 67426fce83f818ba3593f4d1\n",
      "Updated document with _id: 67426fce83f818ba3593f4da\n",
      "Updated document with _id: 67426fce83f818ba3593f4f9\n",
      "Updated document with _id: 67426fce83f818ba3593f50c\n",
      "Updated document with _id: 67426fce83f818ba3593f4e8\n",
      "Updated document with _id: 67426fce83f818ba3593f4ff\n",
      "Updated document with _id: 67426fce83f818ba3593f507\n",
      "Updated document with _id: 67426fce83f818ba3593f4d4\n",
      "Updated document with _id: 67426fce83f818ba3593f4df\n",
      "Updated document with _id: 67426fce83f818ba3593f4e0\n",
      "Updated document with _id: 67426fce83f818ba3593f509\n",
      "Updated document with _id: 67426fce83f818ba3593f4d3\n",
      "Updated document with _id: 67426fce83f818ba3593f4db\n",
      "Updated document with _id: 67426fce83f818ba3593f4e1\n",
      "Updated document with _id: 67426fce83f818ba3593f4fa\n",
      "Updated document with _id: 67426fce83f818ba3593f500\n",
      "Updated document with _id: 67426fce83f818ba3593f50a\n",
      "Updated document with _id: 67426fce83f818ba3593f515\n",
      "Updated document with _id: 6743bb052a0c1abf3501541b\n",
      "Updated document with _id: 6743bb052a0c1abf3501541d\n",
      "Updated document with _id: 6743bb052a0c1abf3501541f\n",
      "Updated document with _id: 6743bb052a0c1abf35015420\n",
      "Updated document with _id: 6743bb052a0c1abf3501542d\n",
      "Updated document with _id: 6743bb052a0c1abf35015434\n",
      "Updated document with _id: 6743d9db7f380c8c98b9fb21\n",
      "Updated document with _id: 6743d9dc7f380c8c98b9fb44\n",
      "Updated document with _id: 6743d9dc7f380c8c98b9fb45\n",
      "Updated document with _id: 6743d9dc7f380c8c98b9fb46\n",
      "Updated document with _id: 6743d9dc7f380c8c98b9fb47\n",
      "Updated document with _id: 6743dabd7f380c8c98b9fb4b\n",
      "All NaN and None values have been replaced with 'N/A'.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://user1:12345@cluster0.s5hw0.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "db = client[\"robo_advisor\"]\n",
    "collection = db[\"asset_metadata\"]\n",
    "\n",
    "# Fetch all documents\n",
    "documents = collection.find()  # Retrieve all documents\n",
    "\n",
    "for doc in documents:\n",
    "    update_needed = False\n",
    "    update_fields = {}\n",
    "\n",
    "    # Check for \"Dividend Frequency\" field\n",
    "    if \"Dividend Frequency\" in doc:\n",
    "        if doc[\"Dividend Frequency\"] is None or isinstance(doc[\"Dividend Frequency\"], float) and np.isnan(doc[\"Dividend Frequency\"]):\n",
    "            update_fields[\"Dividend Frequency\"] = \"N/A\"\n",
    "            update_needed = True\n",
    "\n",
    "    # Check for \"Average Dividend per Share\" field\n",
    "    if \"Average Dividend per Share\" in doc:\n",
    "        if doc[\"Average Dividend per Share\"] is None or isinstance(doc[\"Average Dividend per Share\"], float) and np.isnan(doc[\"Average Dividend per Share\"]):\n",
    "            update_fields[\"Average Dividend per Share\"] = \"N/A\"\n",
    "            update_needed = True\n",
    "\n",
    "    # Perform the update if needed\n",
    "    if update_needed:\n",
    "        collection.update_one({\"_id\": doc[\"_id\"]}, {\"$set\": update_fields})\n",
    "        print(f\"Updated document with _id: {doc['_id']}\")\n",
    "\n",
    "print(\"All NaN and None values have been replaced with 'N/A'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd44620-eb07-429d-8081-e364c86fc00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
