{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Stocks Data**\n",
    "\n",
    "Source: datasets are extracted from https://www.nasdaq.com/ and\n",
    "https://www.macrotrends.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Asset       Close\n",
      "0      1999-05-04    GS     50.5210\n",
      "1      1999-05-05    GS     49.6237\n",
      "2      1999-05-06    GS     48.7695\n",
      "3      1999-05-07    GS     53.2129\n",
      "4      1999-05-10    GS     50.7435\n",
      "...           ...   ...         ...\n",
      "72198  2014-12-02  INDU  17879.5500\n",
      "72199  2014-12-01  INDU  17776.8000\n",
      "72200  2014-11-28  INDU  17828.2400\n",
      "72201  2014-11-27  INDU  17827.7500\n",
      "72202  2014-11-26  INDU  17827.7500\n",
      "\n",
      "[72203 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of file paths with their corresponding asset names\n",
    "file_paths_and_assets = [\n",
    "    (\"../datasets/HistoricalData_GS.csv\", \"GS\"),\n",
    "    (\"../datasets/HistoricalData_MS.csv\", \"MS\"),\n",
    "    (\"../datasets/HistoricalData_UNG.csv\", \"UNG\"),\n",
    "    (\"../datasets/HistoricalData_PDBC.csv\", \"PDBC\"),\n",
    "    (\"../datasets/HistoricalData_INOD.csv\", \"INOD\"),\n",
    "    (\"../datasets/HistoricalData_LBTYB.csv\", \"LBTYB\"),\n",
    "    (\"../datasets/HistoricalData_WLFC.csv\", \"WLFC\"),\n",
    "    (\"../datasets/HistoricalData_AMSC.csv\", \"AMSC\"),\n",
    "    (\"../datasets/HistoricalData_BMA.csv\", \"BMA\"),\n",
    "    (\"../datasets/HistoricalData_USLM.csv\", \"USLM\"),\n",
    "    (\"../datasets/HistoricalData_USD.csv\", \"USD\"),\n",
    "    (\"../datasets/HistoricalData_FNGU.csv\", \"FNGU\"),\n",
    "    (\"../datasets/HistoricalData_NQX.csv\", \"NQX\"),\n",
    "    (\"../datasets/HistoricalData_NDX.csv\", \"NDX\"),\n",
    "    (\"../datasets/HistoricalData_INDU.csv\", \"INDU\")\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store processed DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Process each file\n",
    "for file_path, asset_name in file_paths_and_assets:\n",
    "    try:\n",
    "        # Load the CSV into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add the 'Asset' column\n",
    "        df['Asset'] = asset_name\n",
    "        \n",
    "        # Filter and rename columns\n",
    "        df = df[['Date', 'Asset', 'Close']]\n",
    "\n",
    "        # # Ensure the Date column is in yyyy-mm-dd format\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')  # Convert to datetime, handle errors as NaT\n",
    "        df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')  # Format as yyyy-mm-dd\n",
    "  \n",
    "        # Append the processed DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Combine all processed DataFrames into one\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMSC', 'BMA', 'FNGU', 'GS', 'INDU', 'INOD', 'LBTYB', 'MS', 'NDX', 'NQX', 'PDBC', 'UNG', 'USD', 'USLM', 'WLFC']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(final_df['Asset'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date     0\n",
      "Asset    0\n",
      "Close    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print sum of missing values in each column\n",
    "print(final_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inject data to MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"robo_advisor\"]  # Use the \"robo_advisor\" database\n",
    "collection = db[\"historical_prices\"]  # Use the \"market_data\" collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data successfully inserted into the 'historical_prices' collection.\n"
     ]
    }
   ],
   "source": [
    "# Insert data into MongoDB\n",
    "data_dict = final_df.to_dict(\"records\")  # Convert DataFrame to list of dictionaries\n",
    "collection.insert_many(data_dict)  # Insert into the \"market_data\" collection\n",
    "\n",
    "print(\"data successfully inserted into the 'historical_prices' collection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
